{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS START --\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "# -- IMPORTS END --\n",
    "\n",
    "# enable zooming into graphs\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions:\n",
    "\n",
    "**unix_to_date:**\n",
    "- Converts Epoch(Unix) Time into traditional DateTime information\n",
    "\n",
    "**starter/starter_g:**\n",
    "- applies all necessary cleaning to eliminate null instances, unnecessary columns, etc.\n",
    "- returns working DataFrame with relevant information\n",
    "\n",
    "**calc_magnitude**\n",
    "- Takes individual(x,y,z) accelerometer information and combines it into a singular magnitude\n",
    "\n",
    "**combine**\n",
    "- Takes acceleration dataframe and combines it with gyroscope dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unix_to_date(x):\n",
    "    f = float(x)/10**9\n",
    "    full = datetime.datetime.fromtimestamp(f)\n",
    "    return full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude  \n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starter(filepath):\n",
    "    df = pd.read_csv(filepath, dtype={'time': 'float64'})\n",
    "    df.dropna(inplace=True)\n",
    "    df['time'] = df['time'].apply(unix_to_date)\n",
    "    df = df.drop(['seconds_elapsed'], axis=1)\n",
    "    df = df.reindex(columns=['time', 'x', 'y', 'z'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starter_g(filepath):\n",
    "    df = pd.read_csv(filepath, dtype={'time': 'float64'})\n",
    "    df.dropna(inplace=True)\n",
    "    df['time'] = df['time'].apply(unix_to_date)\n",
    "    df.rename(columns={'x': 'x_gyro'},inplace=True)\n",
    "    df.rename(columns={'y': 'y_gyro'},inplace=True)\n",
    "    df.rename(columns={'z': 'z_gyro'},inplace=True)\n",
    "\n",
    "    df = df.drop(['seconds_elapsed'], axis=1)\n",
    "    df = df.reindex(columns=['time', 'x_gyro', 'y_gyro', 'z_gyro'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(acg,gyro):\n",
    "    combined_df = pd.merge(acg,gyro,on=\"time\",how='left')\n",
    "    combined_df.drop_duplicates(subset=acg, inplace=True)\n",
    "    combined_df = combined_df.dropna()\n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 4 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize model - Do not modify\n",
    "def viz_tree(dt_model,features_frames,cnames):\n",
    "    # Fix feature names as list\n",
    "    feature_names = features_frames.columns.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    tree.plot_tree(dt_model,  \n",
    "                   feature_names=feature_names,\n",
    "                   fontsize=7,\n",
    "                   class_names=cnames,\n",
    "                   filled=True,\n",
    "                   ax=ax)\n",
    "\n",
    "    plt.title('Decision Tree')\n",
    "    plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['accel_mag'].mean()\n",
    "    features['max'] = window['accel_mag'].quantile(1)\n",
    "    features['med'] = window['accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['accel_mag'].quantile(0)\n",
    "    features['q25'] = window['accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['accel_mag'].std()\n",
    "    features['xg_avg'] = window['x_gyro'].mean()\n",
    "    features['yg_avg'] = window['y_gyro'].mean()\n",
    "    features['zg_avg'] = window['z_gyro'].mean()\n",
    "\n",
    "    df = pd.DataFrame([features])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns \n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std','xg_avg','yg_avg','zg_avg']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['label']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract windows and features \n",
    "def extract_features(data, window_sec, sample_rate, activity):\n",
    "    # TODO - see instructions above\n",
    "    \n",
    "    window_size = window_sec * sample_rate\n",
    "    step = window_size // 2\n",
    "\n",
    "    resampled_data = pd.DataFrame()\n",
    "\n",
    "    final_step = len(data) - window_size\n",
    "\n",
    "    for start in range(0, final_step, step):\n",
    "        window = data.iloc[start:start + window_size]\n",
    "        frame = add_features(window)\n",
    "        frame[\"label\"] = activity\n",
    "        \n",
    "        resampled_data = pd.concat([resampled_data, frame], ignore_index=True)\n",
    "    \n",
    "\n",
    "    return resampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_to_combined_csv():\n",
    "    import os\n",
    "    import sys\n",
    "    import glob\n",
    "    # TODO - see instructions above\n",
    "    # there is nothing to return from this function. \n",
    "    # The function is writing something to a file instead.\n",
    "    activity_paths = []\n",
    "    data_path = 'data'\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for directory in dirs:\n",
    "            activity_path = os.path.join(root, directory)\n",
    "            activity_paths.append(glob.glob(activity_path))\n",
    "                    \n",
    "    sampling_rate = 500\n",
    "    window_sec = 3\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for data_path in activity_paths:\n",
    "        activity = os.path.basename(os.path.normpath(str(data_path[0])))\n",
    "        accel_file = os.path.join(data_path[0], \"Accelerometer.csv\")\n",
    "        gyro_file = os.path.join(data_path[0], \"Gyroscope.csv\")\n",
    "        accel_data = starter(accel_file)\n",
    "        calc_magnitude(accel_data)\n",
    "        gyro_data = starter_g(gyro_file)\n",
    "        data = combine(accel_data, gyro_data)\n",
    "        data = remove_noise(data, sampling_rate)\n",
    "        feature_frame = extract_features(data, window_sec, sampling_rate, activity)\n",
    "        all_data = pd.concat([all_data, feature_frame], ignore_index=True)\n",
    "    \n",
    "    all_data.to_csv('data/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _________________________________________________\n",
    "### Reading Training Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFa = starter(\"data/Forehand/Accelerometer.csv\")\n",
    "calc_magnitude(newFa)\n",
    "newFg = starter_g(\"data/Forehand/Gyroscope.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSa = starter(\"data/Serve/Accelerometer.csv\")\n",
    "calc_magnitude(newSa)\n",
    "newSg = starter_g(\"data/Serve/Gyroscope.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBa = starter(\"data/Backhand/Accelerometer.csv\")\n",
    "calc_magnitude(newBa)\n",
    "newBg = starter_g(\"data/Backhand/Gyroscope.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ______________________________\n",
    "### Swing Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_plotter(df):\n",
    "    df.plot(x='time',y='x')\n",
    "    df.plot(x='time',y='y')\n",
    "    df.plot(x='time',y='z')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanB = remove_noise(combine(newBa,newBg),500)\n",
    "cleanF = remove_noise(combine(newFa,newFg),500)\n",
    "cleanS = remove_noise(combine(newSa,newSg),500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "dfs = [newBa,newFa,newSa,cleanB,cleanF,cleanS]\n",
    "\n",
    "for i in range(0,2):\n",
    "    for j in range(0,3):\n",
    "        if(i == 0):\n",
    "            axs[i,j].plot(dfs[j]['time'],dfs[j]['accel_mag'])\n",
    "        else:\n",
    "            axs[i,j].plot(dfs[j]['time'],dfs[j+3]['filtered_accel_mag'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Different Swings\n",
    "\n",
    "1. **Backhand**: To do this, modify the `drop_activities` list to only include 'Backhand'. Run the training code and note the accuracy.\n",
    "\n",
    "2. **Forehand**: Next, modify the `drop_activities` list to only include 'Forehand'. Run the training code and note the accuracy.\n",
    "\n",
    "3. **Serve**: For this run, modify the `drop_activities` list to only include 'Serve'. Run the training code and note the accuracy.\n",
    "\n",
    "4. **Backhand & Forehand**: For this run, modify the `drop_activities` list to only include 'Backhand' and 'Forehand'. Run the training code and note the accuracy.\n",
    "\n",
    "5. **Backhand & Serve**: For this run, modify the `drop_activities` list to only include 'Backhand' and 'Serve'. Run the training code and note the accuracy.\n",
    "\n",
    "6. **Forehand & Serve**: For this run, modify the `drop_activities` list to only include 'Forehand' and 'Serve'. Run the training code and note the accuracy.\n",
    "\n",
    "4. **All Activities**: Finally, clear the `drop_activities` list so that all activities are included in the training process. Run the training code and note the accuracy.\n",
    "\n",
    "For each experiment, the depth of the decision tree is 5. \n",
    "\n",
    "| Model trained on | Accuracy |\n",
    "|-|-|\n",
    "| Backhand | 0.635 |\n",
    "| Forehand | 0.884 | \n",
    "| Serve | 0.671 |\n",
    "| Backhand & Forehand | 0.671 |\n",
    "| Backhand & Serve | 0.671 |\n",
    "| Forehand & Serve | 0.671 |\n",
    "| All Swings | 0.648 |\n",
    "|-|-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset that extracts features from all the files and labels them with the corresponding activity\n",
    "# This function will only create the all_data.csv file once. If you want to overwrite, delete the file first.\n",
    "all_data_to_combined_csv()\n",
    "\n",
    "feature_frames = pd.read_csv('data/all_data.csv')\n",
    "\n",
    "# Activities to drop - pick a subset of the below activities to drop and see how accuracy changes\n",
    "#drop_activities = ['Backhand']\n",
    "#drop_activities = ['Forehand']\n",
    "#drop_activities = ['Serve']\n",
    "#drop_activities = ['Backhand', 'Forehand']\n",
    "#drop_activities = ['Backhand', 'Serve]\n",
    "#drop_activities = ['Forehand', 'Serve']\n",
    "drop_activities = []\n",
    "\n",
    "# TODO: Invert mask to keep only other rows\n",
    "\n",
    "for acti in drop_activities:\n",
    "     feature_frames = feature_frames.drop(feature_frames[feature_frames['label'] == acti].index)\n",
    "\n",
    "# TODO: Train the decision tree with the chosen classes\n",
    "dt_model,dt_cm,acc = train_decision_tree(feature_frames)\n",
    "\n",
    "# This function will print out precision/recall/accuracy\n",
    "\n",
    "# TODO: Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "with open('dt_model.pkl', 'wb') as f:\n",
    "     pickle.dump(dt_model, f)\n",
    "\n",
    "# TODO: Display the confusion matrix\n",
    "print(dt_cm)\n",
    "# TODO: Visualize the tree\n",
    "viz_tree(dt_model,feature_frames,feature_frames['label'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
